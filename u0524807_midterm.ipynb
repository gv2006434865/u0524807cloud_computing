{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "set(['setosa', 'versicolor', 'virginica'])\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt, zeros\n",
    "import numpy as np\n",
    "# read the first 4 columns\n",
    "data = genfromtxt('iris.csv',delimiter=',',usecols=(0,1,2,3))\n",
    "# read the fifth column\n",
    "target = genfromtxt('iris.csv',delimiter=',',usecols=(4),dtype=str)\n",
    "print data.shape\n",
    "print target.shape\n",
    "print set (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = zeros(len(target))\n",
    "t[target == 'setosa'] = 1\n",
    "t[target == 'versicolor'] = 2\n",
    "t[target == 'virginica'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "train, test, t_train, t_test = cross_validation.train_test_split(data, t\n",
    ", test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier1 = GradientBoostingClassifier().fit(data,t)\n",
    "classifier2 = GradientBoostingClassifier().fit(train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.10000000000000001, 5, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "rate = np.arange(0.1, 1.1,0.1)\n",
    "ne = np.arange(5,10,5)\n",
    "gs=0.0\n",
    "i=0\n",
    "gscores = []\n",
    "for r in rate:\n",
    "    classifier1.set_params(learning_rate=r)\n",
    "    classifier2.set_params(learning_rate=r)\n",
    "    r1=r\n",
    "    for n in ne:\n",
    "        classifier1.set_params(n_estimators=n)\n",
    "        classifier2.set_params(n_estimators=n)\n",
    "        n1=n\n",
    "        classifier1.fit(data,t)\n",
    "        classifier2.fit(train,t_train)\n",
    "        gs1=classifier1.score(data,t)\n",
    "        gs2=classifier2.score(test,t_test)\n",
    "        i=i+1\n",
    "        if gs1>gs:\n",
    "            gs=gs1\n",
    "            print (i, r1, n1, gs1, gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=5, learning_rate=1,max_depth=1, random_state=0).fit(data,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(data,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(train,t_train) \n",
    "print classifier.score(test,t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print confusion_matrix(classifier.predict(test),t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        11\n",
      " versicolor       1.00      1.00      1.00        13\n",
      "  virginica       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(classifier.predict(test), t_test,\n",
    "target_names=['setosa', 'versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
